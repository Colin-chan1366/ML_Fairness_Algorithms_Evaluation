{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic with constrains\n",
        "\n",
        "Essay github: https://github.com/mbilalzafar/fair-classification\n",
        "\n",
        "Essay : Maximizing accuracy under fairness constraints"
      ],
      "metadata": {
        "id": "7DR1egsJuCNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary library"
      ],
      "metadata": {
        "id": "soTrkGvtuKxC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o0Evpu-M0yUb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import utils as ut\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import loss_funcs as lf\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from scipy.optimize import fmin_slsqp\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions"
      ],
      "metadata": {
        "id": "joTAI_OMuO_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_p_rule(x_control, class_labels):\n",
        "\n",
        "    \"\"\" Compute the p-rule based on Doctrine of disparate impact \"\"\"\n",
        "\n",
        "    non_prot_all = sum(x_control == 1.0) # non-protected group\n",
        "    prot_all = sum(x_control == 0.0) # protected group\n",
        "    non_prot_pos = sum(class_labels[x_control == 1.0] == 1.0) # non_protected in positive class\n",
        "    prot_pos = sum(class_labels[x_control == 0.0] == 1.0) # protected in positive class\n",
        "    frac_non_prot_pos = float(non_prot_pos) / float(non_prot_all)\n",
        "    frac_prot_pos = float(prot_pos) / float(prot_all)\n",
        "    p_rule = min((frac_non_prot_pos / frac_prot_pos) , (frac_prot_pos / frac_non_prot_pos))* 100.0\n",
        "\n",
        "    return p_rule\n",
        "\n",
        "def calculate_calibration_difference(model, X_test, y_test, sensitive_test, n_bins=10):\n",
        "\n",
        "    # Predict the probabilities on the test set\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
        "\n",
        "    # Get the indices for each group\n",
        "    group1_idx = (sensitive_test == 1)\n",
        "    group2_idx = (sensitive_test == 0)\n",
        "\n",
        "    # Calculate the calibration curve for each group\n",
        "    prob_true_group1, prob_pred_group1 = calibration_curve(y_test[group1_idx], y_prob[group1_idx], n_bins=n_bins, strategy='uniform')\n",
        "    prob_true_group2, prob_pred_group2 = calibration_curve(y_test[group2_idx], y_prob[group2_idx], n_bins=n_bins, strategy='uniform')\n",
        "\n",
        "    # Calculate the calibration difference\n",
        "    calibration_difference = np.abs(prob_true_group1 - prob_true_group2)\n",
        "\n",
        "    # Calculate the average calibration difference across bins\n",
        "    average_calibration_difference = np.mean(calibration_difference)\n",
        "\n",
        "    return average_calibration_difference"
      ],
      "metadata": {
        "id": "e-0xUmFblw2G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and filter Dataset"
      ],
      "metadata": {
        "id": "Vr7GvRfKuTrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "# Load the dataset\n",
        "file_path = '/content/compas-scores-two-years.csv'\n",
        "compas_data = pd.read_csv(file_path)\n",
        "\n",
        "# Getting attributes we want\n",
        "selected_var=[\"sex\",\"age\",\"race\",\"juv_fel_count\",\"decile_score\",\"juv_misd_count\",\"juv_other_count\",\"priors_count\",\"c_days_from_compas\",\"c_charge_degree\",\"decile_score\",\"v_decile_score\",\"priors_count\",\"two_year_recid\"]\n",
        "\n",
        "# Converting some of the features to be binary or categorical\n",
        "compas_data=compas_data[selected_var]\n",
        "filtered_data = compas_data[compas_data['race'].isin(['Caucasian', 'African-American'])]\n",
        "filtered_data['race'] = filtered_data['race'].apply(lambda x: 1 if x == 'Caucasian' else 0)\n",
        "filtered_data['class_label'] = filtered_data['two_year_recid'].apply(lambda x: 1 if x else 0)\n",
        "filtered_data['sex'] = filtered_data['sex'].apply(lambda x: 1 if x == \"Male\" else 0)\n",
        "filtered_data['c_charge_degree'] = filtered_data['c_charge_degree'].apply(lambda x: 1 if x == \"M\" else 0)\n",
        "filtered_data.head(5)\n",
        "\n",
        "# drop NaN data\n",
        "filtered_data=filtered_data.dropna()"
      ],
      "metadata": {
        "id": "ZSXI_EM13Q48"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test split"
      ],
      "metadata": {
        "id": "3rJZXoRqufT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train test split\n",
        "filtered_data=filtered_data.drop(columns=[\"two_year_recid\"])\n",
        "y=filtered_data.class_label\n",
        "x=filtered_data.drop(columns=[\"class_label\",\"race\"])\n",
        "sensitive_attribute = filtered_data['race']\n",
        "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(x, y, sensitive_attribute, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "7TX2QsPD3c3A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline: Logistic Regression"
      ],
      "metadata": {
        "id": "lyf240qOun8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline: Logistic Regression\n",
        "np.random.seed(110)\n",
        "w = ut.train_model(X_train,\n",
        "                   y_train,\n",
        "                   x_control = {'race': sensitive_train},\n",
        "                   loss_function = lf._logistic_loss,\n",
        "                   apply_fairness_constraints = 0,\n",
        "                   apply_accuracy_constraint = 0,\n",
        "                   sep_constraint = 0,\n",
        "                   sensitive_attrs = ['race'],\n",
        "                   sensitive_attrs_to_cov_thresh = {'race': 0},\n",
        "                   gamma = None)"
      ],
      "metadata": {
        "id": "5IZlj3qW5LVb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic Regression:')\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "model = LogisticRegression().fit(X_train, y_train)\n",
        "lr_p_train = compute_p_rule(sensitive_train, model.predict(X_train))\n",
        "lr_p_test = compute_p_rule(sensitive_test, model.predict(X_test))\n",
        "lr_train_accuracy = model.score(X_train, y_train) * 100\n",
        "lr_test_accuracy = model.score(X_test, y_test) * 100\n",
        "lr_calibration = calculate_calibration_difference(model, X_test, y_test, sensitive_test, n_bins=10)\n",
        "\n",
        "# Print out accuracies\n",
        "print()\n",
        "print(\"Accuracy (%)\")\n",
        "print(\"Training: {:.2f}%\".format(lr_train_accuracy))\n",
        "print(\"Test: {:.2f}%\".format(lr_test_accuracy))\n",
        "print()\n",
        "print(\"p_rule (%)\")\n",
        "print(\"Training: {:.2f}%\".format(lr_p_train))\n",
        "print(\"Test: {:.2f}%\".format(lr_p_test))\n",
        "print()\n",
        "print(\"Calibtraion (%)\")\n",
        "print(\"Test:{:.4f}%\".format(lr_calibration))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSjju3SomEgQ",
        "outputId": "b8d1072d-db78-4636-97bd-6149a3cd9f08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "\n",
            "Accuracy (%)\n",
            "Training: 68.01%\n",
            "Test: 68.44%\n",
            "\n",
            "p_rule (%)\n",
            "Training: 53.20%\n",
            "Test: 49.61%\n",
            "\n",
            "Calibtraion (%)\n",
            "Test:0.0577%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing classifier accuracy subject to fairness constraints"
      ],
      "metadata": {
        "id": "dkn2s5xfuvm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizing classifier accuracy subject to fairness constraints\n",
        "np.random.seed(150)\n",
        "w = ut.train_model(X_train,\n",
        "                   y_train,\n",
        "                   x_control = {'race': sensitive_train},\n",
        "                   loss_function = lf._logistic_loss,\n",
        "                   apply_fairness_constraints = 1,\n",
        "                   apply_accuracy_constraint = 0,\n",
        "                   sep_constraint = 0,\n",
        "                   sensitive_attrs = ['race'],\n",
        "                   sensitive_attrs_to_cov_thresh = {'race': 0},\n",
        "                   gamma = None)"
      ],
      "metadata": {
        "id": "5MWzNkQdNfZc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding model with weights\n",
        "m = LogisticRegression()\n",
        "m.coef_= w.reshape((1,-1))\n",
        "m.intercept_ = 0\n",
        "m.classes_ = np.array([0, 1])"
      ],
      "metadata": {
        "id": "bR1ILJzldwuH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic Regression with fairness constraints:')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "LRFC_p_train = compute_p_rule(sensitive_train, m.predict(X_train))\n",
        "LRFC_p_test = compute_p_rule(sensitive_test, m.predict(X_test))\n",
        "LRFC_train_accuracy = m.score(X_train, y_train) * 100\n",
        "LRFC_test_accuracy = m.score(X_test, y_test) * 100\n",
        "LRFC_calibration = calculate_calibration_difference(m, X_test, y_test, sensitive_test, n_bins=10)\n",
        "\n",
        "# Print out accuracies\n",
        "print()\n",
        "print(\"Accuracy (%)\")\n",
        "print(\"Training: {:.2f}%\".format(LRFC_train_accuracy))\n",
        "print(\"Test: {:.2f}%\".format(LRFC_test_accuracy))\n",
        "print()\n",
        "print(\"p_rule (%)\")\n",
        "print(\"Training: {:.2f}%\".format(LRFC_p_train))\n",
        "print(\"Test: {:.2f}%\".format(LRFC_p_test))\n",
        "print()\n",
        "print(\"Calibtraion (%)\")\n",
        "print(\"Test:{:.4f}%\".format(LRFC_calibration))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGOqRtk6eDpS",
        "outputId": "8e014c50-1694-4465-d6a8-3c0f7a5561f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with fairness constraints:\n",
            "\n",
            "Accuracy (%)\n",
            "Training: 46.01%\n",
            "Test: 48.02%\n",
            "\n",
            "p_rule (%)\n",
            "Training: 99.96%\n",
            "Test: 99.91%\n",
            "\n",
            "Calibtraion (%)\n",
            "Test:0.2646%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing classifier fariness subject to accuracy constraints"
      ],
      "metadata": {
        "id": "uHdirDqSu5Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(110)\n",
        "w = ut.train_model(X_train,\n",
        "                   y_train,\n",
        "                   x_control = {'race': sensitive_train},\n",
        "                   loss_function = lf._logistic_loss,\n",
        "                   apply_fairness_constraints = 0,\n",
        "                   apply_accuracy_constraint = 1,\n",
        "                   sep_constraint = 0,\n",
        "                   sensitive_attrs = ['race'],\n",
        "                   sensitive_attrs_to_cov_thresh = {'race': 0},\n",
        "                   gamma = 0.8)"
      ],
      "metadata": {
        "id": "rQlEQPyoeNu6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding model with coefficients and weights\n",
        "m = LogisticRegression()\n",
        "m.coef_= w.reshape((1,-1))\n",
        "m.intercept_ = 0\n",
        "m.classes_ = np.array([0, 1])"
      ],
      "metadata": {
        "id": "wrPjqlWleSBd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic Regression with accuracy constraints:')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "LRAC_p_train = compute_p_rule(sensitive_train, m.predict(X_train))\n",
        "LRAC_p_test = compute_p_rule(sensitive_test, m.predict(X_test))\n",
        "LRAC_train_accuracy = m.score(X_train, y_train) * 100\n",
        "LRAC_test_accuracy = m.score(X_test, y_test) * 100\n",
        "LRAC_calibration = calculate_calibration_difference(m, X_test, y_test, sensitive_test, n_bins=10)\n",
        "\n",
        "# Print out accuracies\n",
        "print()\n",
        "print(\"Accuracy (%)\")\n",
        "print(\"Training: {:.2f}%\".format(LRAC_train_accuracy))\n",
        "print(\"Test: {:.2f}%\".format(LRAC_test_accuracy))\n",
        "print()\n",
        "print(\"p_rule (%)\")\n",
        "print(\"Training: {:.2f}%\".format(LRAC_p_train))\n",
        "print(\"Test: {:.2f}%\".format(LRAC_p_test))\n",
        "print()\n",
        "print(\"Calibtraion (%)\")\n",
        "print(\"Test:{:.4f}%\".format(LRAC_calibration))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ds07mQveTom",
        "outputId": "6fe24303-3a99-4885-89b8-0ae4a8585886"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with accuracy constraints:\n",
            "\n",
            "Accuracy (%)\n",
            "Training: 45.98%\n",
            "Test: 47.96%\n",
            "\n",
            "p_rule (%)\n",
            "Training: 100.00%\n",
            "Test: 100.00%\n",
            "\n",
            "Calibtraion (%)\n",
            "Test:0.1241%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "OTQt7NYlvCyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_data = [\n",
        "    {'Model': 'Logitstic Regression', 'Accuracy_Train (%)': lr_train_accuracy, 'Accuracy_Test (%)': lr_test_accuracy, 'P_Rule_Train (%)': lr_p_train, 'P_Rule_Test (%)': lr_p_test, 'Calibration_Test (%)': lr_calibration},\n",
        "    {'Model': 'LRC', 'Accuracy_Train (%)': LRFC_train_accuracy, 'Accuracy_Test (%)': LRFC_test_accuracy, 'P_Rule_Train (%)': LRFC_p_train, 'P_Rule_Test (%)': LRFC_p_test, 'Calibration_Test (%)': LRFC_calibration},\n",
        "    {'Model': 'LRAC', 'Accuracy_Train (%)': LRAC_train_accuracy, 'Accuracy_Test (%)': LRAC_test_accuracy, 'P_Rule_Train (%)': LRAC_p_train, 'P_Rule_Test (%)': LRAC_p_test, 'Calibration_Test (%)': LRAC_calibration}\n",
        "]\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(models_data)\n",
        "\n",
        "# Reorder DataFrame to have 'Model' column first\n",
        "df = df[['Model', 'Accuracy_Train (%)', 'Accuracy_Test (%)', 'P_Rule_Train (%)', 'P_Rule_Test (%)', 'Calibration_Test (%)']]\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uuA77V1zUMo",
        "outputId": "dd08c31a-bc8a-4b9b-8e0d-a7e988a250b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Model  Accuracy_Train (%)  Accuracy_Test (%)  P_Rule_Train (%)  P_Rule_Test (%)  Calibration_Test (%)\n",
            "Logitstic Regression           68.009313          68.441065         53.203465        49.607920              0.057688\n",
            "                 LRC           46.006985          48.017382         99.961165        99.910072              0.264626\n",
            "                LRAC           45.983702          47.963064        100.000000       100.000000              0.124113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with constraints have really good p rule even their accuracy is not that high.\n",
        "\n",
        "**We believe that logistic regression with constrains is better.**\n",
        "\n",
        "\n",
        "We can notice that baseline(logistic regression) has highest Accuracy but low P_rule. This shows that inequity exists in BASELINE, which may result in serious consequences, especially on a topic like RACE.\n",
        "\n",
        "\n",
        "As to whether to choose the constrain of ACCURACY or the constrain of FAIRNESS, you need to choose the model according to the actual situation. For example, like the current topic related to race, we think that a higher p-rule value can avoid the potential risk of racial discrimination."
      ],
      "metadata": {
        "id": "N4d04Vry1hsa"
      }
    }
  ]
}